{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591d7d4c",
   "metadata": {},
   "source": [
    "## BiLSTM-CRF를 이용한 개체명 인식\n",
    "기존의 양방향 LSTM 모델에 CRF(Conditional Random Field)라는 새로운 층을 추가하여 보다 모델을 개선시킨 양방향 LSTM + CRF 모델을 사용하여 개체명 인식(Named Entity Recognition)을 수행합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6699b",
   "metadata": {},
   "source": [
    "### 1. CRF(Conditional Random Field)\n",
    "CRF는 Conditional Random Field의 약자로 양방향 LSTM을 위해 탄생한 모델이 아니라 이전에 독자적으로 존재해왔던 모델입니다. 이를 양방향 LSTM 모델 위에 하나의 층으로 추가하여, 양방향 LSTM + CRF 모델이 탄생하였습니다. 여기서는 CRF의 수식적 이해가 아니라 양방향 LSTM + CRF 모델의 직관에 대해서 이해합니다.\n",
    "\n",
    "CRF 층의 역할을 이해하기 위해서 간단한 개체명 인식 작업의 예를 들어보겠습니다. 사람(Person), 조직(Organization) 두 가지만을 태깅하는 간단한 태깅 작업에 BIO 표현을 사용한다면 여기서 사용하는 태깅의 종류는 아래의 5가지입니다.\n",
    "\n",
    "```\n",
    "B-Per, I-Per, B-Org, I-Org, O\n",
    "```\n",
    "BIO 표현에 따르면 우선, 첫번째 단어의 레이블에서 I가 등장할 수 없습니다. 또한 I-Per은 반드시 B-Per 뒤에서만 등장할 수 있습니다. 뿐만 아니라, I-Org도 마찬가지로 B-Org 뒤에서만 등장할 수 있는데 BiLSTM모델은 이런 BIO 표현 방법의 제약사항들을 지킬 수 없습니다.\n",
    "\n",
    "여기서 양방향 LSTM 위에 CRF 층을 추가하여 얻을 수 있는 이점을 언급하겠습니다. CRF 층을 추가하면 모델은 예측 개체명, 다시 말해 레이블 사이의 의존성을 고려할 수 있습니다.\n",
    "\n",
    "기존에 CRF 층이 존재하지 않았던 양방향 LSTM 모델은 활성화 함수를 지난 시점에서 개체명을 결정했지만, CRF 층을 추가한 모델에서는 활성화 함수의 결과들이 CRF 층의 입력으로 전달됩니다. 예를 들어 에 대한 양방향 LSTM 셀과 활성화 함수를 지난 출력값 [0.7, 0.12, 0.08, 0.04, 0.06]은 CRF 층의 입력이 됩니다. 마찬가지로 모든 단어에 대한 활성화 함수를 지난 출력값은 CRF 층의 입력이 되고, CRF 층은 레이블 시퀀스에 대해서 가장 높은 점수를 가지는 시퀀스를 예측합니다.\n",
    "\n",
    "이러한 구조에서 CRF 층은 점차적으로 훈련 데이터로부터 아래와 같은 제약사항 등을 학습하게 됩니다.\n",
    "\n",
    "1. 문장의 첫번째 단어에서는 I가 나오지 않습니다.\n",
    "2. O-I 패턴은 나오지 않습니다.\n",
    "3. B-I-I 패턴에서 개체명은 일관성을 유지합니다. 예를 들어 B-Per 다음에 I-Org는 나오지 않습니다.\n",
    "\n",
    "요약하면 양방향 LSTM은 입력 단어에 대한 양방향 문맥을 반영하며, CRF는 출력 레이블에 대한 양방향 문맥을 반영합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0fde7",
   "metadata": {},
   "source": [
    "### 2. 개체명 인식 데이터에 대한 이해와 전처리\n",
    "앞서 사용한 데이터와는 다른 데이터를 사용하여 개체명 인식을 수행해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61ff037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 17:32:44.510612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-08 17:32:44.510649: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47532295",
   "metadata": {},
   "source": [
    "#### 1) 데이터 로드하기\n",
    "데이터는 아래의 링크에서 다운로드합니다.\n",
    "\n",
    "링크 : https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2065ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20Sequence%20Labeling/dataset/ner_dataset.csv\", filename=\"data/ner_data/ner_dataset.csv\")\n",
    "data = pd.read_csv(\"data/ner_data/ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b6313",
   "metadata": {},
   "source": [
    "5개만  출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e06762c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc57594",
   "metadata": {},
   "source": [
    "데이터의 형식을 이해해봅시다. 첫번째 열 'Sentence :#'은 다음과 같은 패턴을 가지고 있습니다. Sentence: 1이 등장하고 Null 값이 이어지다가 다시 Sentence: 2가 등장하고 다시 Null 값이 이어지다가 Sentence: 3이 등장하고 다시 Null 값이 이어지다가를 반복합니다.  \n",
    "  \n",
    "사실 이는 하나의 문장을 여러 행으로 나눠놓은 것입니다. 숫자값을 t라고 합시다. 첫번째 Sentence: t부터 Null 값이 나오다가 Sentence: t+1이 나오기 전까지의 모든 행은 기존에 하나의 문장이었습니다. t번째 문장을 단어 토큰화 후 각 행으로 나눠놓은 데이터이기 때문입니다.  \n",
    "\n",
    "뒤에서 Pandas의 fillna를 통해 하나로 묶는 작업을 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037c5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터프레임 행의 개수 : 1048575\n"
     ]
    }
   ],
   "source": [
    "print('데이터프레임 행의 개수 : {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b09a40",
   "metadata": {},
   "source": [
    "#### 2) 데이터 정제하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e6443",
   "metadata": {},
   "source": [
    "현재 data의 행의 개수는 1,048,575개입니다. 하지만 뒤에서 문장 1개를 다수의 행들으로 나누어 놓은 것을 다시 1개의 행으로 병합하는 작업을 해야하기 때문에 최종 샘플의 개수는 이보다 줄어들게 됩니다.\n",
    "  \n",
    "결측값 유무를 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb1841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터에 Null 값이 있는지 유무 : True\n"
     ]
    }
   ],
   "source": [
    "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfe345",
   "metadata": {},
   "source": [
    "Sentence #열에 Null 값들이 존재하고 있어 isnull().values.any()를 수행하였을 때 True가 나옵니다. isnull().sum()을 수행하면 각 열마다의 Null 값의 개수를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f58ed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어떤 열에 Null값이 있는지 출력\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('어떤 열에 Null값이 있는지 출력')\n",
    "print('==============================')\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbe6d4",
   "metadata": {},
   "source": [
    "다른 열은 0개인데 오직 Sentences #열에서만 1,000,616개가 나온 것을 볼 수 있습니다.  \n",
    "  \n",
    "전체 데이터에서 중복을 허용하지 않고 유일한 값의 개수를 셀 수 있게 해주는 nunique()를 사용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26dad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence # 열의 중복을 제거한 값의 개수 : 47959\n",
      "Word 열의 중복을 제거한 값의 개수 : 35178\n",
      "Tag 열의 중복을 제거한 값의 개수 : 17\n"
     ]
    }
   ],
   "source": [
    "print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n",
    "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n",
    "print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3b119",
   "metadata": {},
   "source": [
    "이 데이터에는 47,959개의 문장이 있으며 문장들은 35,178개의 단어를 가지고 17개 종류의 개체명 태깅을 가집니다.  \n",
    "  \n",
    "17개의 개체명 태깅이 전체 데이터에서 몇 개가 있는지, 개체명 태깅 개수의 분포를 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60cc1a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 열의 각각의 값의 개수 카운트\n",
      "================================\n",
      "      Tag   count\n",
      "0   B-art     402\n",
      "1   B-eve     308\n",
      "2   B-geo   37644\n",
      "3   B-gpe   15870\n",
      "4   B-nat     201\n",
      "5   B-org   20143\n",
      "6   B-per   16990\n",
      "7   B-tim   20333\n",
      "8   I-art     297\n",
      "9   I-eve     253\n",
      "10  I-geo    7414\n",
      "11  I-gpe     198\n",
      "12  I-nat      51\n",
      "13  I-org   16784\n",
      "14  I-per   17251\n",
      "15  I-tim    6528\n",
      "16      O  887908\n"
     ]
    }
   ],
   "source": [
    "print('Tag 열의 각각의 값의 개수 카운트')\n",
    "print('================================')\n",
    "print(data.groupby('Tag').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844698e8",
   "metadata": {},
   "source": [
    "BIO 표현 방법에서 아무런 태깅도 의미하지 않는 O가 가장 887,908개로 가장 많은 개수를 차지함을 볼 수 있습니다.  \n",
    "  \n",
    "데이터를 원하는 형태로 가공해보겠습니다. 우선 Null 값을 제거합니다.  \n",
    "Pandas의 fillna(method='ffill')는 Null 값을 가진 행의 바로 앞의 행의 값으로 Null 값을 채우는 작업을 수행합니다. t번째 문장에 속하면서 Null 값을 가진 샘플들은 전부 첫번째 열에 Sentence: t의 값이 들어갑니다. 이번에는 뒤의 5개의 샘플을 출력해서 정상적으로 수행되었는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179d5d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Sentence #       Word  POS Tag\n",
      "1048570  Sentence: 47959       they  PRP   O\n",
      "1048571  Sentence: 47959  responded  VBD   O\n",
      "1048572  Sentence: 47959         to   TO   O\n",
      "1048573  Sentence: 47959        the   DT   O\n",
      "1048574  Sentence: 47959     attack   NN   O\n"
     ]
    }
   ],
   "source": [
    "data = data.fillna(method=\"ffill\")\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229981f",
   "metadata": {},
   "source": [
    "뒤의 5개 샘플의 첫번째 열이 Sentence: 47959로 채워졌습니다.  \n",
    "이는 47,959번째 문장임을 의미하며, Null 값을 가진 행들의 바로 앞 행의 Sentence # 열의 값이 Sentence: 47959이었음을 의미합니다.  \n",
    "  \n",
    "전체 데이터에 Null 값이 존재하는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61336af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터에 Null 값이 있는지 유무 : False\n"
     ]
    }
   ],
   "source": [
    "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e781726",
   "metadata": {},
   "source": [
    "없는 것으로 나옵니다.  \n",
    "  \n",
    "모든 단어를 소문자화하여 단어의 개수를 줄여보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bcba82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 열의 중복을 제거한 값의 개수 : 31817\n"
     ]
    }
   ],
   "source": [
    "data['Word'] = data['Word'].str.lower()\n",
    "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634f719",
   "metadata": {},
   "source": [
    "정상적으로 소문자화가 되었는지 앞의 샘플 5개만 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2577e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      thousands  NNS   O\n",
      "1  Sentence: 1             of   IN   O\n",
      "2  Sentence: 1  demonstrators  NNS   O\n",
      "3  Sentence: 1           have  VBP   O\n",
      "4  Sentence: 1        marched  VBN   O\n"
     ]
    }
   ],
   "source": [
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392ece2",
   "metadata": {},
   "source": [
    "하나의 문장에 등장한 단어와 개체명 태깅 정보끼리 쌍(pair)으로 묶는 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "317706ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수: 47959\n"
     ]
    }
   ],
   "source": [
    "func = lambda temp: [(w, t) for w, t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
    "tagged_sentences=[t for t in data.groupby(\"Sentence #\").apply(func)]\n",
    "print(\"전체 샘플 개수: {}\".format(len(tagged_sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0ad72",
   "metadata": {},
   "source": [
    "1,000,616개의 행의 개수가 각 문장당 하나의 샘플로 묶이면서 47,959개의 샘플이 되었습니다.  \n",
    "\n",
    "정상적으로 수행되었는지 첫번째 샘플을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ef1f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0]) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756588b",
   "metadata": {},
   "source": [
    "전처리가 수행된 첫번째 샘플이 출력됩니다. 이러한 샘플이 총 47,959개가 있습니다. 그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리시켜야 합니다. 즉, [('thousands', 'O'), ('of', 'O')]와 같은 문장 샘플이 있다면 thousands와 of는 같이 저장하고, O와 O를 같이 저장할 필요가 있습니다.  \n",
    "\n",
    "동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 하는 zip()을 사용하여 단어와 개체명 태깅 정보를 분리해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf640cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, ner_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\n",
    "\n",
    "    # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
    "    sentence, tag_info = zip(*tagged_sentence) \n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080023f",
   "metadata": {},
   "source": [
    "각 문장 샘플에서 단어는 sentences에 태깅 정보는 ner_tags에 저장하였습니다.  \n",
    "\n",
    "임의로 첫번째 문장 샘플을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc0f078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(ner_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833bab7",
   "metadata": {},
   "source": [
    "첫번째 샘플에 대해서 단어에 대해서만 sentences[0]에, 또한 개체명에 대해서만 ner_tags[0]에 저장된 것을 볼 수 있습니다. 뒤에서 보겠지만, sentences는 예측을 위한 X에 해당되며 ner_tags는 예측 대상인 y에 해당됩니다.  \n",
    "\n",
    "다른 샘플들에 대해서도 처리가 되었는지 확인하기 위해 임의로 98번 인덱스의 샘플에 대해서도 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f9ef9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'had', 'once', 'received', 'a', 'kidney', 'transplant', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[98])\n",
    "print(ner_tags[98])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406f61e",
   "metadata": {},
   "source": [
    "단어에 대해서만 sentences[98]에, 또한 개체명에 대해서만 ner_tags[98]에 저장된 것을 확인할 수 있습니다. 또한 첫번째 샘플과 길이가 다릅니다. 47,959개의 문장 샘플의 길이는 서로 다를 수 있습니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e4057",
   "metadata": {},
   "source": [
    "#### 3) 정수 인코딩\n",
    "\n",
    "전체 데이터의 길이 분포를 확인해봅시다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf04ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 104\n",
      "샘플의 평균 길이 : 21.863988\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897089e",
   "metadata": {},
   "source": [
    "위의 그래프는 샘플들의 길이가 대체적으로 0~40의 길이를 가지는 것을 보여줍니다. 길이가 가장 긴 샘플의 길이는 104입니다.  \n",
    "\n",
    "케라스 토크나이저를 통해서 정수 인코딩을 진행합니다. 이번에는 문장 데이터에 있는 모든 단어를 사용하겠습니다.  \n",
    "토크나이저를 초기화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf29c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 단어를 사용하며 인덱스 1에는 단어 'OOV'를 할당.\n",
    "src_tokenizer = Tokenizer(oov_token='OOV')\n",
    "# 태깅 정보들은 내부적으로 대문자를 유지한 채 저장\n",
    "tar_tokenizer = Tokenizer(lower=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c393459",
   "metadata": {},
   "source": [
    "문장 데이터에 있는 모든 단어를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd3edae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer.fit_on_texts(sentences)\n",
    "tar_tokenizer.fit_on_texts(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ebba3",
   "metadata": {},
   "source": [
    "문장 데이터에 대해서는 src_tokenizer를, 레이블에 해당되는 개체명 태깅 정보에 대해서는 tar_tokenizer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbfc08b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 31819\n",
      "개체명 태깅 정보 집합의 크기 : 18\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f8b21",
   "metadata": {},
   "source": [
    "앞서 src_tokenizer를 만들때 Tokenizer의 인자로 oov_token='OOV'를 선택했습니다. 인덱스1에 단어 'OOV'가 할당됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e5aa8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 OOV의 인덱스 : 1\n"
     ]
    }
   ],
   "source": [
    "print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5d7eb",
   "metadata": {},
   "source": [
    "정수 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18f7553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473c137",
   "metadata": {},
   "source": [
    "문장 데이터에 대해서 정수 인코딩이 수행된 결과는 X_data, 개체명 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 y_data에 저장되었습니다.\n",
    "\n",
    "정수 인코딩이 되었는지 확인을 위해 임의로 2번 인덱스 샘플을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba45c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3], [327, 36, 27, 48, 1773, 7, 766, 1005, 7, 4424, 3184, 771, 6, 2, 1165, 84, 4, 43, 25, 1650, 2189, 454, 2190, 6016, 3]]\n",
      "[[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1], [8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_data[:2])\n",
    "print(y_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f2f28e",
   "metadata": {},
   "source": [
    "모델 훈련 후 결과 확인을 위해 인덱스로부터 단어를 리턴하는 index_to_word와 인덱스로부터 개체명 태깅 정보를 리턴하는 index_to_ner를 만듭니다.  \n",
    "\n",
    "인덱스 0은 'PAD'란 단어를 할당해둡니다. index_to_ner은 개수가 적으니 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19c9aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = src_tokenizer.word_index\n",
    "index_to_word = src_tokenizer.index_word\n",
    "ner_to_index = tar_tokenizer.word_index\n",
    "index_to_ner = tar_tokenizer.index_word\n",
    "index_to_ner[0] = 'PAD'\n",
    "\n",
    "print(index_to_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669b6cc",
   "metadata": {},
   "source": [
    "index_to_word를 통해 첫번째 샘플의 정수 시퀀스를 텍스트 시퀀스로 변환하는 디코딩 작업을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93c28764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for index in X_data[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
    "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
    "\n",
    "print('기존의 문장 : {}'.format(sentences[0]))\n",
    "print('디코딩 문장 : {}'.format(decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac910e8",
   "metadata": {},
   "source": [
    "X 데이터와 y 데이터가 구성되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fdc001",
   "metadata": {},
   "source": [
    "#### 4) 패딩\n",
    "서로 다른 길이의 샘플들의 길이를 동일하게 맞춰주는 패딩 작업을 진행해보겠습니다. 앞서 확인하였듯이 대부분의 데이터의 길이는 40~60에 분포되어져 있습니다. 그러므로 가장 긴 샘플의 길이인 104가 아니라 70정도로 max_len을 정해보겠습니다. X에 해당되는 데이터 X_data의 샘플들과 y에 해당되는 데이터 y_data 샘플들의 모든 길이를 임의로 70정도로 맞추어 보겠습니다.  \n",
    "\n",
    "케라스의 pad_sequences()를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be0ae492",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
    "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b99618",
   "metadata": {},
   "source": [
    "모든 샘플의 길이가 70이 되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f6ba3",
   "metadata": {},
   "source": [
    "#### 5) 학습데이터와 테스트 데이터 분리\n",
    "사이킷런(scikit-learn)의 model_selection 패키지 안에 train_test_split 모듈을 활용하여 손쉽게 train set(학습 데이터 셋)과 test set(테스트 셋)을 분리할 수 있습니다.  \n",
    "\n",
    "훈련 데이터와 테스트 데이터를 8:2의 비율로 분리합니다.\n",
    "  \n",
    "**옵션 값 설명**\n",
    " - test_size: 테스트 셋 구성의 비율을 나타냅니다. train_size의 옵션과 반대 관계에 있는 옵션 값이며, 주로 test_size를 지정해 줍니다. 0.2는 전체 데이터 셋의 20%를 test (validation) 셋으로 지정하겠다는 의미입니다. default 값은 0.25 입니다.\n",
    " - shuffle: default=True 입니다. split을 해주기 이전에 섞을건지 여부입니다. 보통은 default 값으로 놔둡니다.\n",
    " - stratify: default=None 입니다. classification을 다룰 때 매우 중요한 옵션값입니다. stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해 줍니다. (한 쪽에 쏠려서 분배되는 것을 방지합니다) 만약 이 옵션을 지정해 주지 않고 classification 문제를 다룬다면, 성능의 차이가 많이 날 수 있습니다.\n",
    " - random_state: 세트를 섞을 때 해당 int 값을 보고 섞으며, 하이퍼 파라미터를 튜닝시 이 값을 고정해두고 튜닝해야 매번 데이터셋이 변경되는 것을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e084904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_int, y_test_int = train_test_split(X_data, y_data, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e78f6",
   "metadata": {},
   "source": [
    "정답 레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행합니다. 케라스는 정수 인코딩 된 결과로부터 원-핫 인코딩을 수행하는 to_categorical()를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82bfc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test_int, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874f690",
   "metadata": {},
   "source": [
    "각 데이터 크기를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b0df029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (38367, 70)\n",
      "훈련 샘플 레이블(정수 인코딩)의 크기 : (38367, 70)\n",
      "훈련 샘플 레이블(원-핫 인코딩)의 크기 : (38367, 70, 18)\n",
      "테스트 샘플 문장의 크기 : (9592, 70)\n",
      "테스트 샘플 레이블(정수 인코딩)의 크기 : (9592, 70)\n",
      "테스트 샘플 레이블(원-핫 인코딩)의 크기 : (9592, 70, 18)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_train_int.shape))\n",
    "print('훈련 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_test_int.shape))\n",
    "print('테스트 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0035fca",
   "metadata": {},
   "source": [
    "### 3. BiLSTM-CRF를 이용한 개체명 인식\n",
    "마지막 층에 CRF 층을 추가하기 위하여 함수형 API를 사용합니다. 하이퍼파라미터인 임베딩 벡터의 차원은 128, 은닉 상태의 크기는 64입니다. 모델은 다 대 다 구조의 양방향 LSTM을 사용합니다. 이 경우 LSTM의 return_sequences의 인자값은 True로 주어야만 합니다. 출력층에 TimeDistributed()를 사용했는데, TimeDistributed()는 LSTM을 다 대 다 구조로 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용할 필요가 있을 때 사용합니다.\n",
    "\n",
    "해당 모델은 모든 시점에 대해서 개체명 레이블 개수만큼의 선택지 중 하나를 예측하는 다중 클래스 분류 문제를 수행하는 모델입니다. 여기서는 최종 출력층이 CRF 층으로 CRF 층에 분류해야 하는 선택지 개수를 의미하는 tag_size를 전달해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caeb91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 17:34:10.135795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-08 17:34:10.135833: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-08 17:34:10.135847: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-41K4BMT): /proc/driver/nvidia/version does not exist\n",
      "2022-04-08 17:34:10.138497: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras_crf import CRFModel\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_units = 64\n",
    "dropout_ratio = 0.3\n",
    "\n",
    "sequence_input = Input(shape=(max_len,),dtype=tf.int32, name='sequence_input')\n",
    "\n",
    "model_embedding = Embedding(input_dim=vocab_size,\n",
    "                            output_dim=embedding_dim,\n",
    "                            input_length=max_len)(sequence_input)\n",
    "\n",
    "model_bilstm = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(model_embedding)\n",
    "\n",
    "model_dropout = TimeDistributed(Dropout(dropout_ratio))(model_bilstm)\n",
    "\n",
    "model_dense = TimeDistributed(Dense(tag_size, activation='relu'))(model_dropout)\n",
    "\n",
    "base = Model(inputs=sequence_input, outputs=model_dense)\n",
    "model = CRFModel(base, tag_size)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d05ba",
   "metadata": {},
   "source": [
    "하이퍼파라미터인 배치 크기는 128이며, 15 에포크를 수행합니다. validation_split=0.1을 사용하여 훈련 데이터의 10%를 검증 데이터로 분리해서 사용하고, 검증 데이터를 통해서 훈련이 적절히 되고 있는지 확인합니다. 검증 데이터는 기계가 훈련 데이터에 과적합되고 있지는 않은지 확인하기 위한 용도로 사용됩니다. 조기 종료를 사용하기 위해서 콜백을 정의합니다. keras-crf가 원-핫 인코딩 된 레이블은 지원하지 않으므로 y_train이 아니라 y_train_int를 사용함을 주의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a0e9e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9082 - loss: 29.7885\n",
      "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.95853, saving model to bilstm_crf/cp.ckpt\n",
      "270/270 [==============================] - 34s 113ms/step - decode_sequence_accuracy: 0.9082 - loss: 29.7145 - val_decode_sequence_accuracy: 0.9585 - val_loss: 9.9968\n",
      "Epoch 2/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9701 - loss: 6.8359\n",
      "Epoch 2: val_decode_sequence_accuracy improved from 0.95853 to 0.98057, saving model to bilstm_crf/cp.ckpt\n",
      "270/270 [==============================] - 30s 110ms/step - decode_sequence_accuracy: 0.9701 - loss: 6.8272 - val_decode_sequence_accuracy: 0.9806 - val_loss: 4.6800\n",
      "Epoch 3/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9837 - loss: 3.5201\n",
      "Epoch 3: val_decode_sequence_accuracy improved from 0.98057 to 0.98419, saving model to bilstm_crf/cp.ckpt\n",
      "270/270 [==============================] - 30s 111ms/step - decode_sequence_accuracy: 0.9837 - loss: 3.5178 - val_decode_sequence_accuracy: 0.9842 - val_loss: 3.2919\n",
      "Epoch 4/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9870 - loss: 2.5072\n",
      "Epoch 4: val_decode_sequence_accuracy improved from 0.98419 to 0.98521, saving model to bilstm_crf/cp.ckpt\n",
      "270/270 [==============================] - 31s 113ms/step - decode_sequence_accuracy: 0.9870 - loss: 2.5101 - val_decode_sequence_accuracy: 0.9852 - val_loss: 3.1727\n",
      "Epoch 5/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9888 - loss: 2.0163\n",
      "Epoch 5: val_decode_sequence_accuracy improved from 0.98521 to 0.98537, saving model to bilstm_crf/cp.ckpt\n",
      "270/270 [==============================] - 30s 113ms/step - decode_sequence_accuracy: 0.9888 - loss: 2.0166 - val_decode_sequence_accuracy: 0.9854 - val_loss: 3.0221\n",
      "Epoch 6/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9899 - loss: 1.7077\n",
      "Epoch 6: val_decode_sequence_accuracy improved from 0.98537 to 0.98542, saving model to bilstm_crf/cp.ckpt\n",
      "270/270 [==============================] - 30s 110ms/step - decode_sequence_accuracy: 0.9899 - loss: 1.7062 - val_decode_sequence_accuracy: 0.9854 - val_loss: 3.0693\n",
      "Epoch 7/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9908 - loss: 1.4806\n",
      "Epoch 7: val_decode_sequence_accuracy improved from 0.98542 to 0.98552, saving model to bilstm_crf/cp.ckpt\n",
      "270/270 [==============================] - 30s 111ms/step - decode_sequence_accuracy: 0.9908 - loss: 1.4800 - val_decode_sequence_accuracy: 0.9855 - val_loss: 3.1054\n",
      "Epoch 8/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9915 - loss: 1.3041\n",
      "Epoch 8: val_decode_sequence_accuracy did not improve from 0.98552\n",
      "270/270 [==============================] - 30s 110ms/step - decode_sequence_accuracy: 0.9915 - loss: 1.3039 - val_decode_sequence_accuracy: 0.9851 - val_loss: 3.3723\n",
      "Epoch 9/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9922 - loss: 1.1484\n",
      "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98552\n",
      "270/270 [==============================] - 30s 110ms/step - decode_sequence_accuracy: 0.9922 - loss: 1.1491 - val_decode_sequence_accuracy: 0.9846 - val_loss: 3.4509\n",
      "Epoch 9: early stopping\n",
      "0:04:33\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "import time \n",
    "import datetime \n",
    "\n",
    "start = time.time()  \n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])\n",
    "\n",
    "end = time.time() \n",
    "\n",
    "sec = (end - start) \n",
    "req_time = str(datetime.timedelta(seconds=sec)).split(\".\") \n",
    "print(\"+\"*10) \n",
    "print(\"모델학습 소요시간 : \",req_time[0]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e449eff",
   "metadata": {},
   "source": [
    "조기 종료로 학습이 끝났다면 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치를 불러온 후, 임의로 선정한 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7fdf15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "the              : O       O\n",
      "statement        : O       O\n",
      "came             : O       O\n",
      "as               : O       O\n",
      "u.n.             : B-org   B-org\n",
      "secretary-general: I-org   I-org\n",
      "kofi             : B-per   B-per\n",
      "annan            : I-per   I-per\n",
      "met              : O       O\n",
      "with             : O       O\n",
      "officials        : O       O\n",
      "in               : O       O\n",
      "amman            : B-geo   B-geo\n",
      "to               : O       O\n",
      "discuss          : O       O\n",
      "wednesday        : B-tim   B-tim\n",
      "'s               : O       O\n",
      "attacks          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('bilstm_crf/cp.ckpt')\n",
    "\n",
    "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]]))[0] # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "labels = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34765db0",
   "metadata": {},
   "source": [
    "정확하게 잘 예측한 것 같습니다. 테스트 데이터에 대해서 성능을 측정해봅시다. 테스트 데이터에 대한 예측 시퀀스인 y_predicted를 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58a1cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba5650",
   "metadata": {},
   "source": [
    "상위 2개만 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5f2460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3 10  1  4  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  1  1  1  1  3  1  1  1  1  1  1  1  2  9  9  1  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_predicted[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8d9a4",
   "metadata": {},
   "source": [
    "예측값으로 확률 벡터가 아니라 정수 시퀀스가 출력됩니다. 이 경우 이전 실습에서 사용했던 함수인 sequences_to_tag를 사용할 수 없으므로 함수를 수정해야 합니다. 확률 벡터가 아닌 정수 시퀀스를 입력으로 받아서 태깅 정보 시퀀스를 리턴하는 함수로 sequences_to_tag_for_crf를 만듭니다. 해당 함수를 사용하여 예측값과 레이블에 해당하는 y_test를 태깅 정보 시퀀스로 변환하여 F1-score를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ba2d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''F1-score를 계산하기 위해서 개체명 태깅의 확률 벡터 또는 원-핫 벡터로부터 \n",
    "태깅 정보 시퀀스로 변환하는 함수인 sequences_to_tag를 만듭니다. \n",
    "해당 함수를 통해 모델의 예측값인 y_predicted와 실제값에 해당하는 y_test를 태깅 정보 시퀀스로 변환합니다. \n",
    "그리고 두 개를 비교하여 f1-score를 계산합니다.'''\n",
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences:\n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.\n",
    "        for pred in sequence:\n",
    "            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            pred_index = np.argmax(pred)            \n",
    "            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
    "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8956572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 79.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/PJT/000NLP/nlp_env/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.50      0.02      0.03        63\n",
      "         eve       1.00      0.12      0.21        52\n",
      "         geo       0.83      0.84      0.83      7620\n",
      "         gpe       0.95      0.93      0.94      3145\n",
      "         nat       0.00      0.00      0.00        37\n",
      "         org       0.64      0.59      0.61      4033\n",
      "         per       0.77      0.70      0.73      3545\n",
      "         tim       0.86      0.84      0.85      4067\n",
      "\n",
      "   micro avg       0.81      0.78      0.79     22562\n",
      "   macro avg       0.69      0.50      0.53     22562\n",
      "weighted avg       0.81      0.78      0.79     22562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sequences_to_tag_for_crf(sequences): \n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences: \n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 예측 정수 레이블을 하나씩 꺼낸다.\n",
    "        for pred_index in sequence:\n",
    "            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
    "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result\n",
    "\n",
    "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d9771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
