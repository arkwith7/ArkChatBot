{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591d7d4c",
   "metadata": {},
   "source": [
    "## BiLSTM을 이용한 개체명 인식(Named Entity Recognition, NER)\n",
    "양방향 LSTM을 이용하여 개체명 인식기를 만든 후에 F1-score를 사용하여 모델을 평가합니다.\n",
    "\n",
    "### 1. 개체명 인식 데이터에 대한 이해와 전처리\n",
    "앞서 사용한 데이터와는 다른 데이터를 사용하여 개체명 인식을 수행해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61ff037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 16:31:03.631727: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-08 16:31:03.631769: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47532295",
   "metadata": {},
   "source": [
    "#### 1) 데이터 로드하기\n",
    "데이터는 아래의 링크에서 다운로드합니다.\n",
    "\n",
    "링크 : https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2065ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20Sequence%20Labeling/dataset/ner_dataset.csv\", filename=\"data/ner_data/ner_dataset.csv\")\n",
    "data = pd.read_csv(\"data/ner_data/ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b6313",
   "metadata": {},
   "source": [
    "5개만  출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e06762c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc57594",
   "metadata": {},
   "source": [
    "데이터의 형식을 이해해봅시다. 첫번째 열 'Sentence :#'은 다음과 같은 패턴을 가지고 있습니다. Sentence: 1이 등장하고 Null 값이 이어지다가 다시 Sentence: 2가 등장하고 다시 Null 값이 이어지다가 Sentence: 3이 등장하고 다시 Null 값이 이어지다가를 반복합니다.  \n",
    "  \n",
    "사실 이는 하나의 문장을 여러 행으로 나눠놓은 것입니다. 숫자값을 t라고 합시다. 첫번째 Sentence: t부터 Null 값이 나오다가 Sentence: t+1이 나오기 전까지의 모든 행은 기존에 하나의 문장이었습니다. t번째 문장을 단어 토큰화 후 각 행으로 나눠놓은 데이터이기 때문입니다.  \n",
    "\n",
    "뒤에서 Pandas의 fillna를 통해 하나로 묶는 작업을 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037c5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터프레임 행의 개수 : 1048575\n"
     ]
    }
   ],
   "source": [
    "print('데이터프레임 행의 개수 : {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b09a40",
   "metadata": {},
   "source": [
    "#### 2) 데이터 정제하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e6443",
   "metadata": {},
   "source": [
    "현재 data의 행의 개수는 1,048,575개입니다. 하지만 뒤에서 문장 1개를 다수의 행들으로 나누어 놓은 것을 다시 1개의 행으로 병합하는 작업을 해야하기 때문에 최종 샘플의 개수는 이보다 줄어들게 됩니다.\n",
    "  \n",
    "결측값 유무를 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb1841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터에 Null 값이 있는지 유무 : True\n"
     ]
    }
   ],
   "source": [
    "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfe345",
   "metadata": {},
   "source": [
    "Sentence #열에 Null 값들이 존재하고 있어 isnull().values.any()를 수행하였을 때 True가 나옵니다. isnull().sum()을 수행하면 각 열마다의 Null 값의 개수를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f58ed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어떤 열에 Null값이 있는지 출력\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('어떤 열에 Null값이 있는지 출력')\n",
    "print('==============================')\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbe6d4",
   "metadata": {},
   "source": [
    "다른 열은 0개인데 오직 Sentences #열에서만 1,000,616개가 나온 것을 볼 수 있습니다.  \n",
    "  \n",
    "전체 데이터에서 중복을 허용하지 않고 유일한 값의 개수를 셀 수 있게 해주는 nunique()를 사용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26dad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence # 열의 중복을 제거한 값의 개수 : 47959\n",
      "Word 열의 중복을 제거한 값의 개수 : 35178\n",
      "Tag 열의 중복을 제거한 값의 개수 : 17\n"
     ]
    }
   ],
   "source": [
    "print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n",
    "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n",
    "print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3b119",
   "metadata": {},
   "source": [
    "이 데이터에는 47,959개의 문장이 있으며 문장들은 35,178개의 단어를 가지고 17개 종류의 개체명 태깅을 가집니다.  \n",
    "  \n",
    "17개의 개체명 태깅이 전체 데이터에서 몇 개가 있는지, 개체명 태깅 개수의 분포를 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60cc1a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 열의 각각의 값의 개수 카운트\n",
      "================================\n",
      "      Tag   count\n",
      "0   B-art     402\n",
      "1   B-eve     308\n",
      "2   B-geo   37644\n",
      "3   B-gpe   15870\n",
      "4   B-nat     201\n",
      "5   B-org   20143\n",
      "6   B-per   16990\n",
      "7   B-tim   20333\n",
      "8   I-art     297\n",
      "9   I-eve     253\n",
      "10  I-geo    7414\n",
      "11  I-gpe     198\n",
      "12  I-nat      51\n",
      "13  I-org   16784\n",
      "14  I-per   17251\n",
      "15  I-tim    6528\n",
      "16      O  887908\n"
     ]
    }
   ],
   "source": [
    "print('Tag 열의 각각의 값의 개수 카운트')\n",
    "print('================================')\n",
    "print(data.groupby('Tag').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043e1d6",
   "metadata": {},
   "source": [
    "BIO 표현 방법에서 아무런 태깅도 의미하지 않는 O가 가장 887,908개로 가장 많은 개수를 차지함을 볼 수 있습니다.  \n",
    "  \n",
    "데이터를 원하는 형태로 가공해보겠습니다. 우선 Null 값을 제거합니다.  \n",
    "Pandas의 fillna(method='ffill')는 Null 값을 가진 행의 바로 앞의 행의 값으로 Null 값을 채우는 작업을 수행합니다. t번째 문장에 속하면서 Null 값을 가진 샘플들은 전부 첫번째 열에 Sentence: t의 값이 들어갑니다. 이번에는 뒤의 5개의 샘플을 출력해서 정상적으로 수행되었는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91e1705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Sentence #       Word  POS Tag\n",
      "1048570  Sentence: 47959       they  PRP   O\n",
      "1048571  Sentence: 47959  responded  VBD   O\n",
      "1048572  Sentence: 47959         to   TO   O\n",
      "1048573  Sentence: 47959        the   DT   O\n",
      "1048574  Sentence: 47959     attack   NN   O\n"
     ]
    }
   ],
   "source": [
    "data = data.fillna(method=\"ffill\")\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546bd656",
   "metadata": {},
   "source": [
    "뒤의 5개 샘플의 첫번째 열이 Sentence: 47959로 채워졌습니다.  \n",
    "이는 47,959번째 문장임을 의미하며, Null 값을 가진 행들의 바로 앞 행의 Sentence # 열의 값이 Sentence: 47959이었음을 의미합니다.  \n",
    "  \n",
    "전체 데이터에 Null 값이 존재하는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de06e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터에 Null 값이 있는지 유무 : False\n"
     ]
    }
   ],
   "source": [
    "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ccaea",
   "metadata": {},
   "source": [
    "없는 것으로 나옵니다.  \n",
    "  \n",
    "모든 단어를 소문자화하여 단어의 개수를 줄여보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55f3786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 열의 중복을 제거한 값의 개수 : 31817\n"
     ]
    }
   ],
   "source": [
    "data['Word'] = data['Word'].str.lower()\n",
    "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e5e55",
   "metadata": {},
   "source": [
    "정상적으로 소문자화가 되었는지 앞의 샘플 5개만 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d5a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      thousands  NNS   O\n",
      "1  Sentence: 1             of   IN   O\n",
      "2  Sentence: 1  demonstrators  NNS   O\n",
      "3  Sentence: 1           have  VBP   O\n",
      "4  Sentence: 1        marched  VBN   O\n"
     ]
    }
   ],
   "source": [
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f11c0",
   "metadata": {},
   "source": [
    "하나의 문장에 등장한 단어와 개체명 태깅 정보끼리 쌍(pair)으로 묶는 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774fdd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수: 47959\n"
     ]
    }
   ],
   "source": [
    "func = lambda temp: [(w, t) for w, t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
    "tagged_sentences=[t for t in data.groupby(\"Sentence #\").apply(func)]\n",
    "print(\"전체 샘플 개수: {}\".format(len(tagged_sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276911f3",
   "metadata": {},
   "source": [
    "1,000,616개의 행의 개수가 각 문장당 하나의 샘플로 묶이면서 47,959개의 샘플이 되었습니다.  \n",
    "\n",
    "정상적으로 수행되었는지 첫번째 샘플을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da72d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0]) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585907c6",
   "metadata": {},
   "source": [
    "전처리가 수행된 첫번째 샘플이 출력됩니다. 이러한 샘플이 총 47,959개가 있습니다. 그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리시켜야 합니다. 즉, [('thousands', 'O'), ('of', 'O')]와 같은 문장 샘플이 있다면 thousands와 of는 같이 저장하고, O와 O를 같이 저장할 필요가 있습니다.  \n",
    "\n",
    "동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 하는 zip()을 사용하여 단어와 개체명 태깅 정보를 분리해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da397de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, ner_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\n",
    "\n",
    "    # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
    "    sentence, tag_info = zip(*tagged_sentence) \n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4b225",
   "metadata": {},
   "source": [
    "각 문장 샘플에서 단어는 sentences에 태깅 정보는 ner_tags에 저장하였습니다.  \n",
    "\n",
    "임의로 첫번째 문장 샘플을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1fbbf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(ner_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d01b8",
   "metadata": {},
   "source": [
    "첫번째 샘플에 대해서 단어에 대해서만 sentences[0]에, 또한 개체명에 대해서만 ner_tags[0]에 저장된 것을 볼 수 있습니다. 뒤에서 보겠지만, sentences는 예측을 위한 X에 해당되며 ner_tags는 예측 대상인 y에 해당됩니다.  \n",
    "\n",
    "다른 샘플들에 대해서도 처리가 되었는지 확인하기 위해 임의로 98번 인덱스의 샘플에 대해서도 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2ca3938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'had', 'once', 'received', 'a', 'kidney', 'transplant', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[98])\n",
    "print(ner_tags[98])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7c24d",
   "metadata": {},
   "source": [
    "단어에 대해서만 sentences[98]에, 또한 개체명에 대해서만 ner_tags[98]에 저장된 것을 확인할 수 있습니다. 또한 첫번째 샘플과 길이가 다릅니다. 47,959개의 문장 샘플의 길이는 서로 다를 수 있습니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e4057",
   "metadata": {},
   "source": [
    "#### 3) 정수 인코딩\n",
    "\n",
    "전체 데이터의 길이 분포를 확인해봅시다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "652da35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 104\n",
      "샘플의 평균 길이 : 21.863988\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618404af",
   "metadata": {},
   "source": [
    "위의 그래프는 샘플들의 길이가 대체적으로 0~40의 길이를 가지는 것을 보여줍니다. 길이가 가장 긴 샘플의 길이는 104입니다.  \n",
    "\n",
    "케라스 토크나이저를 통해서 정수 인코딩을 진행합니다. 이번에는 문장 데이터에 있는 모든 단어를 사용하겠습니다.  \n",
    "토크나이저를 초기화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf29c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 단어를 사용하며 인덱스 1에는 단어 'OOV'를 할당.\n",
    "src_tokenizer = Tokenizer(oov_token='OOV')\n",
    "# 태깅 정보들은 내부적으로 대문자를 유지한 채 저장\n",
    "tar_tokenizer = Tokenizer(lower=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e218a4",
   "metadata": {},
   "source": [
    "문장 데이터에 있는 모든 단어를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c16cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer.fit_on_texts(sentences)\n",
    "tar_tokenizer.fit_on_texts(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2e0df",
   "metadata": {},
   "source": [
    "문장 데이터에 대해서는 src_tokenizer를, 레이블에 해당되는 개체명 태깅 정보에 대해서는 tar_tokenizer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d657df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 31819\n",
      "개체명 태깅 정보 집합의 크기 : 18\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03906a38",
   "metadata": {},
   "source": [
    "앞서 src_tokenizer를 만들때 Tokenizer의 인자로 oov_token='OOV'를 선택했습니다. 인덱스1에 단어 'OOV'가 할당됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e5aa8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 OOV의 인덱스 : 1\n"
     ]
    }
   ],
   "source": [
    "print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5d7eb",
   "metadata": {},
   "source": [
    "정수 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18f7553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473c137",
   "metadata": {},
   "source": [
    "문장 데이터에 대해서 정수 인코딩이 수행된 결과는 X_data, 개체명 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 y_data에 저장되었습니다.\n",
    "\n",
    "정수 인코딩이 되었는지 확인을 위해 임의로 2번 인덱스 샘플을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba45c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3], [327, 36, 27, 48, 1773, 7, 766, 1005, 7, 4424, 3184, 771, 6, 2, 1165, 84, 4, 43, 25, 1650, 2189, 454, 2190, 6016, 3]]\n",
      "[[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1], [8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_data[:2])\n",
    "print(y_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c901cab0",
   "metadata": {},
   "source": [
    "모델 훈련 후 결과 확인을 위해 인덱스로부터 단어를 리턴하는 index_to_word와 인덱스로부터 개체명 태깅 정보를 리턴하는 index_to_ner를 만듭니다.  \n",
    "\n",
    "인덱스 0은 'PAD'란 단어를 할당해둡니다. index_to_ner은 개수가 적으니 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c22f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = src_tokenizer.word_index\n",
    "index_to_word = src_tokenizer.index_word\n",
    "ner_to_index = tar_tokenizer.word_index\n",
    "index_to_ner = tar_tokenizer.index_word\n",
    "index_to_ner[0] = 'PAD'\n",
    "\n",
    "print(index_to_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963eb5c7",
   "metadata": {},
   "source": [
    "index_to_word를 통해 첫번째 샘플의 정수 시퀀스를 텍스트 시퀀스로 변환하는 디코딩 작업을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ad2311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for index in X_data[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
    "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
    "\n",
    "print('기존의 문장 : {}'.format(sentences[0]))\n",
    "print('디코딩 문장 : {}'.format(decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695c609",
   "metadata": {},
   "source": [
    "X 데이터와 y 데이터가 구성되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fdc001",
   "metadata": {},
   "source": [
    "#### 4) 패딩\n",
    "서로 다른 길이의 샘플들의 길이를 동일하게 맞춰주는 패딩 작업을 진행해보겠습니다. 앞서 확인하였듯이 대부분의 데이터의 길이는 40~60에 분포되어져 있습니다. 그러므로 가장 긴 샘플의 길이인 104가 아니라 70정도로 max_len을 정해보겠습니다. X에 해당되는 데이터 X_data의 샘플들과 y에 해당되는 데이터 y_data 샘플들의 모든 길이를 임의로 70정도로 맞추어 보겠습니다.  \n",
    "\n",
    "케라스의 pad_sequences()를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be0ae492",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
    "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a82984",
   "metadata": {},
   "source": [
    "모든 샘플의 길이가 70이 되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f6ba3",
   "metadata": {},
   "source": [
    "#### 5) 학습데이터와 테스트 데이터 분리\n",
    "사이킷런(scikit-learn)의 model_selection 패키지 안에 train_test_split 모듈을 활용하여 손쉽게 train set(학습 데이터 셋)과 test set(테스트 셋)을 분리할 수 있습니다.  \n",
    "\n",
    "훈련 데이터와 테스트 데이터를 8:2의 비율로 분리합니다.\n",
    "  \n",
    "**옵션 값 설명**\n",
    " - test_size: 테스트 셋 구성의 비율을 나타냅니다. train_size의 옵션과 반대 관계에 있는 옵션 값이며, 주로 test_size를 지정해 줍니다. 0.2는 전체 데이터 셋의 20%를 test (validation) 셋으로 지정하겠다는 의미입니다. default 값은 0.25 입니다.\n",
    " - shuffle: default=True 입니다. split을 해주기 이전에 섞을건지 여부입니다. 보통은 default 값으로 놔둡니다.\n",
    " - stratify: default=None 입니다. classification을 다룰 때 매우 중요한 옵션값입니다. stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해 줍니다. (한 쪽에 쏠려서 분배되는 것을 방지합니다) 만약 이 옵션을 지정해 주지 않고 classification 문제를 다룬다면, 성능의 차이가 많이 날 수 있습니다.\n",
    " - random_state: 세트를 섞을 때 해당 int 값을 보고 섞으며, 하이퍼 파라미터를 튜닝시 이 값을 고정해두고 튜닝해야 매번 데이터셋이 변경되는 것을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a05189e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_int, y_test_int = train_test_split(X_data, y_data, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49629e93",
   "metadata": {},
   "source": [
    "정답 레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행합니다. 케라스는 정수 인코딩 된 결과로부터 원-핫 인코딩을 수행하는 to_categorical()를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a663261",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test_int, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3112d41a",
   "metadata": {},
   "source": [
    "각 데이터 크기를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b0df029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (38367, 70)\n",
      "훈련 샘플 레이블(정수 인코딩)의 크기 : (38367, 70)\n",
      "훈련 샘플 레이블(원-핫 인코딩)의 크기 : (38367, 70, 18)\n",
      "테스트 샘플 문장의 크기 : (9592, 70)\n",
      "테스트 샘플 레이블(정수 인코딩)의 크기 : (9592, 70)\n",
      "테스트 샘플 레이블(원-핫 인코딩)의 크기 : (9592, 70, 18)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_train_int.shape))\n",
    "print('훈련 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_test_int.shape))\n",
    "print('테스트 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0035fca",
   "metadata": {},
   "source": [
    "### 2. 양방향 LSTM을 이용한 개체명 인식\n",
    "하이퍼파라미터인 임베딩 벡터의 차원은 128, 은닉 상태의 크기는 256입니다. 모델은 다 대 다 구조의 양방향 LSTM을 사용합니다. 이 경우 LSTM의 return_sequences의 인자값은 True로 주어야만 합니다. 이번 실습과 같이 각 데이터의 길이가 달라서 패딩을 하느라 숫자 0이 많아질 경우에는 Embedding()에 mask_zero=True를 설정하여 숫자 0은 연산에서 제외시킨다는 옵션을 줄 수 있습니다. 출력층에 TimeDistributed()를 사용했는데, TimeDistributed()는 LSTM을 다 대 다 구조로 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용할 필요가 있을 때 사용합니다.\n",
    "\n",
    "해당 모델은 모든 시점에 대해서 개체명 레이블 개수만큼의 선택지 중 하나를 예측하는 다중 클래스 분류 문제를 수행하는 모델입니다. 다중 클래스 분류 문제의 경우, 출력층에 소프트맥스 회귀를 사용해야 하므로 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로 크로스 엔트로피 함수를 사용합니다. 하이퍼파라미터인 배치 크기는 128이며, 6 에포크를 수행합니다. validation_split=0.1을 사용하여 훈련 데이터의 10%를 검증 데이터로 분리해서 사용하고, 검증 데이터를 통해서 훈련이 적절히 되고 있는지 확인합니다. 검증 데이터는 기계가 훈련 데이터에 과적합되고 있지는 않은지 확인하기 위한 용도로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caeb91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 16:32:49.572562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-08 16:32:49.572598: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-08 16:32:49.572613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-41K4BMT): /proc/driver/nvidia/version does not exist\n",
      "2022-04-08 16:32:49.575625: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "270/270 [==============================] - 76s 268ms/step - loss: 0.1722 - accuracy: 0.8763 - val_loss: 0.0765 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "270/270 [==============================] - 73s 270ms/step - loss: 0.0538 - accuracy: 0.9504 - val_loss: 0.0480 - val_accuracy: 0.9543\n",
      "Epoch 3/6\n",
      "270/270 [==============================] - 72s 268ms/step - loss: 0.0368 - accuracy: 0.9647 - val_loss: 0.0448 - val_accuracy: 0.9573\n",
      "Epoch 4/6\n",
      "270/270 [==============================] - 72s 268ms/step - loss: 0.0299 - accuracy: 0.9704 - val_loss: 0.0428 - val_accuracy: 0.9587\n",
      "Epoch 5/6\n",
      "270/270 [==============================] - 72s 267ms/step - loss: 0.0259 - accuracy: 0.9740 - val_loss: 0.0441 - val_accuracy: 0.9588\n",
      "Epoch 6/6\n",
      "270/270 [==============================] - 72s 268ms/step - loss: 0.0228 - accuracy: 0.9766 - val_loss: 0.0452 - val_accuracy: 0.9579\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_units = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d05ba",
   "metadata": {},
   "source": [
    "총 6번의 에포크를 마치고나서 val_accuracy: 0.9586 검증 데이터에 대해서 약 95%의 정확도를 얻습니다.  \n",
    "\n",
    "테스트 데이터의 임의의 인덱스 13번 샘플에 대해서 실제값과 예측값을 비교해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a0e9e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "the              : O       O\n",
      "statement        : O       O\n",
      "came             : O       O\n",
      "as               : O       O\n",
      "u.n.             : B-org   B-org\n",
      "secretary-general: I-org   I-org\n",
      "kofi             : B-per   B-per\n",
      "annan            : I-per   I-per\n",
      "met              : O       O\n",
      "with             : O       O\n",
      "officials        : O       O\n",
      "in               : O       O\n",
      "amman            : B-geo   B-geo\n",
      "to               : O       O\n",
      "discuss          : O       O\n",
      "wednesday        : B-tim   B-tim\n",
      "'s               : O       O\n",
      "attacks          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경함.\n",
    "labels = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98244e",
   "metadata": {},
   "source": [
    "정확하게 예측했습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b79de8",
   "metadata": {},
   "source": [
    "F1-score라는 성능 평가 방법에 대해서 이해하고, 테스트 데이터에 대해서 성능을 측정해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52fe3a",
   "metadata": {},
   "source": [
    "### 3. F1-score\n",
    "개체명 인식에서는 그 어떤 개체도 아니라는 의미의 'O'라는 태깅이 존재합니다. 그런데 이런 정보는 보통 대다수의 레이블을 차지하기 때문에 기존에 사용했던 정확도(accuracy)를 평가 방법으로 사용하는 것이 적절하지 않을 수 있습니다.\n",
    "\n",
    "예를 들어 모델이 단 1개의 개체도 맞추지 못하고 전부 'O'로 예상했을 경우를 봅시다. 실제값은 위에서 출력했던 값을 실제값으로 재사용하겠습니다. 아래 코드에서는 labels라는 변수에 저장하였습니다. 그리고 개체를 하나도 맞추지 못했다는 가정하에 전부 'O'로만 채워진 예측값 predicted를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74dd3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = ['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\n",
    "predicted = ['O'] * len(labels) \n",
    "print('예측값 :',predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25009cb",
   "metadata": {},
   "source": [
    "실제로는 PER, MISC, PER, MISC, PER이라는 총 5개의 개체가 존재함에도 불구하고 예측값인 predicted는 단 1개의 개체도 맞추지 못한 상황을 시뮬레이션하는 것입니다. 이에 대한 정확도를 계산해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b94daa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 74.4%\n"
     ]
    }
   ],
   "source": [
    "hit = 0 # 정답 개수\n",
    "for tag, pred in zip(labels, predicted):\n",
    "    if tag == pred:\n",
    "        hit +=1 # 정답인 경우에만 +1\n",
    "accuracy = hit/len(labels) # 정답 개수를 총 개수로 나눈다.\n",
    "print(\"정확도: {:.1%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f341db9",
   "metadata": {},
   "source": [
    "실제값에서도 대부분의 값이 'O'이기 때문에 그 어떤 개체도 찾지 못하였음에도 74%의 정확도를 얻습니다. 이는 정확도가 뻥튀기되어 모델의 성능을 오해할 수 있다는 문제가 있습니다. 그래서 여기서는 위와 같은 상황에서 더 적절한 평가 방법을 도입하고자 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0f8cd",
   "metadata": {},
   "source": [
    "앞서 머신 러닝 훑어보기 챕터에서 정밀도(precision)과 재현률(recall)을 언급한 바 있습니다. 개체명 인식 모델의 성능 측정을 위해 정밀도와 재현률 개념을 사용해보겠습니다. 이를 개체명 인식 문제에 맞도록 해석해보면 다음과 같습니다.\n",
    "\n",
    "정밀도 $ = \\frac{TP}{TP + FP} = $ 특정 개체라고 예측한 경우중에서 실제 특정 개체로 판명되어 예측이 일치한 비율  \n",
    "참, 거짓 포함 포함해서 맞춘 것들중 참인것으로 맞춘 비율\n",
    "\n",
    "재현률 $ = \\frac{TP}{TP + FN} = $ 전체 특정 개체중에서 실제 특정 개체라고 정답을 맞춘 비율  \n",
    "참, 거짓 포함, 원래 정답인 것들 중에서 참인것으로 맞춘 비율\n",
    "\n",
    "정밀도와 재현률로부터 조화 평균(harmonic mean)을 구한 것을 f1-score라고 합니다.\n",
    "\n",
    "$$f1-score = 2×\\frac{정밀도×재현률}{정밀도＋재현률}$$\n",
    " \n",
    "predicted의 성능을 평가하기 위해서 정밀도, 재현률, f1-score를 계산해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b545a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         2\n",
      "         PER       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.00      0.00      0.00         5\n",
      "   macro avg       0.00      0.00      0.00         5\n",
      "weighted avg       0.00      0.00      0.00         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/PJT/000NLP/nlp_env/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/PJT/000NLP/nlp_env/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report([labels], [predicted]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd777dca",
   "metadata": {},
   "source": [
    "이러한 측정 방법을 사용하면 PER과 MISC 두 특정 개체 중에서 실제 predicted가 맞춘 것은 단 1개도 없는 것을 확인할 수 있습니다. 이번에는 어느 정도는 정답을 맞추었다고 가정하고 예측값인 predicted를 수정하여 정밀도, 재현률, f1-score를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da15500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       1.00      0.50      0.67         2\n",
      "         PER       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       1.00      0.60      0.75         5\n",
      "   macro avg       1.00      0.58      0.73         5\n",
      "weighted avg       1.00      0.60      0.75         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\n",
    "predicted = ['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O']\n",
    "\n",
    "print(classification_report([labels], [predicted]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13f6da",
   "metadata": {},
   "source": [
    "특정 개체로 예측한 경우에 대해서는 모두 제대로 예측을 하였으므로 정밀도는 1이 나옵니다. 하지만 재현률에서는 MISC는 실제로는 4개임에도 2개만을 맞추었으므로 0.5, PER은 실제로는 3개임에도 2개만을 맞추었으므로 0.67이 나온 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31992d5b",
   "metadata": {},
   "source": [
    "### 4. F1-score로 성능 측정하기\n",
    "F1-score를 계산하기 위해서 개체명 태깅의 확률 벡터 또는 원-핫 벡터로부터 태깅 정보 시퀀스로 변환하는 함수인 sequences_to_tag를 만듭니다. 해당 함수를 통해 모델의 예측값인 y_predicted와 실제값에 해당하는 y_test를 태깅 정보 시퀀스로 변환합니다. 그리고 두 개를 비교하여 f1-score를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2ef0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 78.1%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.13      0.03      0.05        63\n",
      "         eve       0.57      0.25      0.35        52\n",
      "         geo       0.81      0.86      0.83      7620\n",
      "         gpe       0.96      0.94      0.95      3145\n",
      "         nat       0.47      0.19      0.27        37\n",
      "         org       0.57      0.57      0.57      4033\n",
      "         per       0.71      0.69      0.70      3545\n",
      "         tim       0.85      0.83      0.84      4067\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     22562\n",
      "   macro avg       0.63      0.55      0.57     22562\n",
      "weighted avg       0.78      0.78      0.78     22562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences:\n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.\n",
    "        for pred in sequence:\n",
    "            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            pred_index = np.argmax(pred)            \n",
    "            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
    "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result\n",
    "\n",
    "y_predicted = model.predict([X_test])\n",
    "pred_tags = sequences_to_tag(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e732962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
