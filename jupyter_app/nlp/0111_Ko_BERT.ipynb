{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f72f170",
   "metadata": {},
   "source": [
    "## 한국어 BERT의 마스크드 언어 모델(Masked Language Model) 실습\n",
    "사전 학습된 한국어 BERT를 이용하여 마스크드 언어 모델을 실습해봅시다. 이번 실습을 위해서만이 아니라 앞으로 사전 학습된 BERT를 사용할 때는 transformers라는 패키지를 자주 사용하게 됩니다. 실습 환경에 transformers 패키지를 설치해둡시다.\n",
    "```\n",
    "pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234d949",
   "metadata": {},
   "source": [
    "### 1. 마스크드 언어 모델과 토크나이저\n",
    "ransformers 패키지를 사용하여 모델과 토크나이저를 로드합니다. BERT는 이미 누군가가 학습해둔 모델을 사용하는 것이므로 우리가 사용하는 모델과 토크나이저는 항상 맵핑 관계여야 합니다. 예를 들어서 A라는 이름의 BERT를 사용하는데, B라는 이름의 BERT의 토크나이저를 사용하면 모델은 텍스트를 제대로 이해할 수 없습니다. A라는 BERT의 토크나이저는 '사과'라는 단어를 36번으로 정수 인코딩하는 반면에, B라는 BERT의 토크나이저는 '사과'라는 단어를 42번으로 정수 인코딩하는 등 단어와 맵핑되는 정수 정보 자체가 다르기 때문입니다.\n",
    "\n",
    "klue/bert-base는 대표적인 한국어 BERT입니다. klue/bert-base의 마스크드 언어 모델과 klue/bert-base의 토크나이저를 로드해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8216232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 10:39:57.390887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-12 10:39:57.390994: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e3c791",
   "metadata": {},
   "source": [
    "TFBertForMaskedLM.from_pretrained('BERT 모델 이름')을 넣으면 [MASK]라고 되어있는 단어를 맞추기 위한 마스크드 언어 모델링을 위한 구조로 BERT를 로드합니다. 다시 말해서 BERT를 마스크드 언어 모델 형태로 로드합니다.\n",
    "  \n",
    "AutoTokenizer.from_pretrained('모델 이름')을 넣으면 해당 모델이 학습되었을 당시에 사용되었던 토크나이저를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafdcb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c2881ddfca4defb4e6ccb464b08bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a864293f6c5420486da5e7b802b808e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.37G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 18:24:14.400932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-11 18:24:14.400966: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-11 18:24:14.400980: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-41K4BMT): /proc/driver/nvidia/version does not exist\n",
      "2022-04-11 18:24:14.403646: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e470c12ac447c6ad146c3686172e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42053822abdf4ffaa13cb60162003e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d943c4ef39f840bf9fc67cf1e8cd80d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFBertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef109cc9",
   "metadata": {},
   "source": [
    "### 2. BERT의 입력\n",
    "''Soccer is a really fun [MASK]'라는 임의의 문장이 있다고 해봅시다. 이를 마스크드 언어 모델의 입력으로 넣으면, 마스크드 언어 모델은 [MASK]의 위치에 해당하는 단어를 예측합니다. 마스크드 언어 모델의 예측 결과를 보기위해서 bert-large-uncased의 토크나이저를 사용하여 해당 문장을 정수 인코딩해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe712bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('Soccer is a really fun [MASK].', return_tensors='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37dd7b",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 input_ids를 통해 정수 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4056f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 101 4715 2003 1037 2428 4569  103 1012  102]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262f92eb",
   "metadata": {},
   "source": [
    "토크나이저로 변환된 결과에서 token_type_ids를 통해서 문장을 구분하는 세그먼트 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b98799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0 0 0 0 0 0 0 0 0]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a168f",
   "metadata": {},
   "source": [
    "현재의 입력은 문장이 두 개가 아니라 한 개이므로 여기서는 문장 길이만큼의 0 시퀀스를 얻습니다. 만약 문장이 두 개였다면 두번째 문장이 시작되는 구간부터는 1의 시퀀스가 나오게 되지만, 여기서는 해당되지 않습니다.\n",
    "  \n",
    "토크나이저로 변환된 결과에서 attention_mask를 통해서 실제 단어와 패딩 토큰을 구분하는 용도인 어텐션 마스크를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6a1b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 1 1 1 1 1 1 1 1]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff916c",
   "metadata": {},
   "source": [
    "현재의 입력에서는 패딩이 없으므로 여기서는 문장 길이만큼의 1 시퀀스를 얻습니다. 만약 뒤에 패딩이 있었다면 패딩이 시작되는 구간부터는 0의 시퀀스가 나오게 되지만, 여기서는 해당되지 않습니다. 좀 더 다양한 패턴의 입력은 뒤의 텍스트 분류, 개체명 인식, 질의 응답 실습에서 이어서 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c644bd",
   "metadata": {},
   "source": [
    "### 3. [MASK] 토큰 예측하기\n",
    "FillMaskPipeline은 모델과 토크나이저를 지정하면 손쉽게 마스크드 언어 모델의 예측 결과를 정리해서 보여줍니다. FillMaskPipeline에 우선 앞서 불러온 모델과 토크나이저를 지정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bdc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14544659",
   "metadata": {},
   "source": [
    "이제 입력 문장으로부터 [MASK]의 위치에 들어갈 수 있는 상위 5개의 후보 단어들을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c64adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7621119618415833,\n",
       "  'token': 4368,\n",
       "  'token_str': 'sport',\n",
       "  'sequence': 'soccer is a really fun sport.'},\n",
       " {'score': 0.20341996848583221,\n",
       "  'token': 2208,\n",
       "  'token_str': 'game',\n",
       "  'sequence': 'soccer is a really fun game.'},\n",
       " {'score': 0.012208551168441772,\n",
       "  'token': 2518,\n",
       "  'token_str': 'thing',\n",
       "  'sequence': 'soccer is a really fun thing.'},\n",
       " {'score': 0.0018630317645147443,\n",
       "  'token': 4023,\n",
       "  'token_str': 'activity',\n",
       "  'sequence': 'soccer is a really fun activity.'},\n",
       " {'score': 0.0013354889815673232,\n",
       "  'token': 2492,\n",
       "  'token_str': 'field',\n",
       "  'sequence': 'soccer is a really fun field.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('Soccer is a really fun [MASK].')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8681fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.25628936290740967,\n",
       "  'token': 2265,\n",
       "  'token_str': 'show',\n",
       "  'sequence': 'the avengers is a really fun show.'},\n",
       " {'score': 0.17284080386161804,\n",
       "  'token': 3185,\n",
       "  'token_str': 'movie',\n",
       "  'sequence': 'the avengers is a really fun movie.'},\n",
       " {'score': 0.11107732355594635,\n",
       "  'token': 2466,\n",
       "  'token_str': 'story',\n",
       "  'sequence': 'the avengers is a really fun story.'},\n",
       " {'score': 0.07248973101377487,\n",
       "  'token': 2186,\n",
       "  'token_str': 'series',\n",
       "  'sequence': 'the avengers is a really fun series.'},\n",
       " {'score': 0.07046627253293991,\n",
       "  'token': 2143,\n",
       "  'token_str': 'film',\n",
       "  'sequence': 'the avengers is a really fun film.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('The Avengers is a really fun [MASK].')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16653659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3573067784309387,\n",
       "  'token': 2147,\n",
       "  'token_str': 'work',\n",
       "  'sequence': 'i went to work this morning.'},\n",
       " {'score': 0.23304471373558044,\n",
       "  'token': 2793,\n",
       "  'token_str': 'bed',\n",
       "  'sequence': 'i went to bed this morning.'},\n",
       " {'score': 0.12845060229301453,\n",
       "  'token': 2082,\n",
       "  'token_str': 'school',\n",
       "  'sequence': 'i went to school this morning.'},\n",
       " {'score': 0.062305811792612076,\n",
       "  'token': 3637,\n",
       "  'token_str': 'sleep',\n",
       "  'sequence': 'i went to sleep this morning.'},\n",
       " {'score': 0.04695264622569084,\n",
       "  'token': 2465,\n",
       "  'token_str': 'class',\n",
       "  'sequence': 'i went to class this morning.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('I went to [MASK] this morning.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016cb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
