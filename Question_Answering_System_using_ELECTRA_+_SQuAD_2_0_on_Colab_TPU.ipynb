{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Answering System using ELECTRA + SQuAD 2.0 on Colab TPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkwith7/ArkChatBot/blob/master/Question_Answering_System_using_ELECTRA_%2B_SQuAD_2_0_on_Colab_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NuGJlpdWtB3"
      },
      "source": [
        "This colab file is created by [Pragnakalp Techlabs](https://www.pragnakalp.com/).\n",
        "\n",
        "You can copy this colab in your drive and then execute the command in given order. For more details check our blog [Question Answering System using ELECTRA + SQuAD on Colab TPU](https://www.pragnakalp.com/nlp-tutorial-qna-electra-squad-colab-tpu)\n",
        "\n",
        "Check all our [NLP Demos on demos.pragnakalp.com](https://demos.pragnakalp.com) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X0BjgFZKhBw"
      },
      "source": [
        "#**Electra Fine-tuning and Prediction on SQUAD 2.0 using Cloud TPU!**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNKb1evSLTqR"
      },
      "source": [
        "## **Overview**\n",
        "**ELECTRA**, is a new method of pre-training language representations.  ELECTRA models are trained to distinguish \"real\" input tokens vs \"fake\" input tokens generated by another neural network which  helps to obtains state-of-the-art results . Review the paper about ELECTRA here: https://openreview.net/pdf?id=r1xMH1BtvB.\n",
        "\n",
        "**SQuAD** Stanford Question Answering Dataset is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n",
        "\n",
        "This colab file shows how to fine-tune ELECTRA on SQuAD dataset, and then how to perform the prediction. Using this you can create your own **Question Answering System.**\n",
        "\n",
        "**Prerequisite** : You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud Storage) bucket to run this colab file.\n",
        "\n",
        "Please follow the Google Cloud for how to create GCP account and GCS bucket. You have $300 free credit to get started with any GCP product. You can learn more about it at https://cloud.google.com/tpu/docs/setup-gcp-account\n",
        "\n",
        "You can create your GCS bucket from here http://console.cloud.google.com/storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5ozva3cuusW"
      },
      "source": [
        "##**Change Runtime to TPU.**\n",
        ">On the main menu, click on Runtime and select Change runtime type. Set \"TPU\" as the hardware accelerator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGyV2VC7CCOQ"
      },
      "source": [
        "## **Clone Repository of ELECTRA.**\n",
        "\n",
        "> First clone the **'electra'** Repository from github by using below command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBvx7_aNBz0V",
        "outputId": "2b77527c-80d8-4e3b-a223-2238de651e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/google-research/electra.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'electra'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 72 (delta 26), reused 58 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (72/72), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmvlctGhNCAS"
      },
      "source": [
        "Use 'cd' command to enter into 'electra' github repo directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0AZBw1lYc6Q",
        "outputId": "ab87458c-d5b0-46e5-e95f-57cee96e124c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd electra"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/electra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a7d7peFNLtK"
      },
      "source": [
        "Use 'ls -l' to see the files inside the given directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSzsdgfipbYE",
        "outputId": "ef4116ee-8d36-4861-fc5f-eb60101a471f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 116\n",
            "-rw-r--r-- 1 root root  3788 Mar 16 06:50 build_openwebtext_pretraining_dataset.py\n",
            "-rw-r--r-- 1 root root  8801 Mar 16 06:50 build_pretraining_dataset.py\n",
            "-rw-r--r-- 1 root root  7607 Mar 16 06:50 configure_finetuning.py\n",
            "-rw-r--r-- 1 root root  5265 Mar 16 06:50 configure_pretraining.py\n",
            "-rw-r--r-- 1 root root  1101 Mar 16 06:50 CONTRIBUTING.md\n",
            "drwxr-xr-x 5 root root  4096 Mar 16 06:50 \u001b[0m\u001b[01;34mfinetune\u001b[0m/\n",
            "-rw-r--r-- 1 root root 11358 Mar 16 06:50 LICENSE\n",
            "drwxr-xr-x 2 root root  4096 Mar 16 06:50 \u001b[01;34mmodel\u001b[0m/\n",
            "drwxr-xr-x 2 root root  4096 Mar 16 06:50 \u001b[01;34mpretrain\u001b[0m/\n",
            "-rw-r--r-- 1 root root 15480 Mar 16 06:50 README.md\n",
            "-rw-r--r-- 1 root root 12663 Mar 16 06:50 run_finetuning.py\n",
            "-rw-r--r-- 1 root root 16518 Mar 16 06:50 run_pretraining.py\n",
            "drwxr-xr-x 2 root root  4096 Mar 16 06:50 \u001b[01;34mutil\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA3obQsmNYDO"
      },
      "source": [
        "##Download Electra base model from Repo.\n",
        "\n",
        "> The Released Model for Electra are as given below:\n",
        "\n",
        "  *    [ELECTRA-Small](https://storage.googleapis.com/electra-data/electra_small.zip)\n",
        "  *   [ELECTRA-Base](https://storage.googleapis.com/electra-data/electra_base.zip)\n",
        "  *   [ELECTRA-Large](https://storage.googleapis.com/electra-data/electra_large.zip)\n",
        "\n",
        "> We are downloading 'ELECTRA-Base' Model by using below command.  \t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR6yc-KrqO1e",
        "outputId": "3f421d44-46c2-4f96-ebd8-0909ca1ac227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/electra-data/electra_base.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-16 06:50:42--  https://storage.googleapis.com/electra-data/electra_base.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c0d::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 885890161 (845M) [application/zip]\n",
            "Saving to: ‘electra_base.zip’\n",
            "\n",
            "electra_base.zip    100%[===================>] 844.85M   245MB/s    in 3.5s    \n",
            "\n",
            "2020-03-16 06:50:46 (241 MB/s) - ‘electra_base.zip’ saved [885890161/885890161]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV8FeULWqaP5",
        "outputId": "0e3557e3-53ca-4a18-8687-24c257a5ad5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#unzip pretrained model\n",
        "!unzip electra_base.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  electra_base.zip\n",
            "   creating: electra_base/\n",
            "  inflating: electra_base/electra_base.meta  \n",
            "  inflating: electra_base/electra_base.index  \n",
            "  inflating: electra_base/checkpoint  \n",
            "  inflating: electra_base/vocab.txt  \n",
            "  inflating: electra_base/electra_base.data-00000-of-00001  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBDprSGGquus",
        "outputId": "7786b92c-b958-49a3-915c-5195044e2bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "#Download the SQUAD train and dev dataset\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-16 06:51:03--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M  48.4MB/s    in 0.8s    \n",
            "\n",
            "2020-03-16 06:51:04 (48.4 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-03-16 06:51:06--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-03-16 06:51:06 (45.2 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf2NAEdOO7aL"
      },
      "source": [
        "Rename SQUAD dataset files name by using below command. We need **'train.json'** for finetuning  and for evaluation '**dev.json'** files as per given **finetuning script** inside electra repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asKf6SarZjf"
      },
      "source": [
        "!mv dev-v2.0.json dev.json\n",
        "!mv train-v2.0.json train.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCjE3IvcvA47"
      },
      "source": [
        "## **Set up your TPU environment:**\n",
        "\n",
        "\n",
        "\n",
        "*   Verify that you are connected to a TPU device.\n",
        "*   You will get know your TPU Address that is used at time of fine-tuning.\n",
        "*   Perform Google Authentication to access your bucket.\n",
        "*   Upload your credentials to TPU to access your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqJ36XiWYiK7",
        "outputId": "89b65dbd-38e5-4a31-951b-fffc4d5e9848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is => ', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "TPU address is =>  grpc://10.53.108.138:8470\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 490528862421994545),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17545060202478104313),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7140905136198066936),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9935863326940108697),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12175906947571916151),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9598849066282411394),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14807287559284357616),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2343830356868686291),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14228466151272117899),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1598348904673419228),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 607195693558712607)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sor6NMQIUz4p"
      },
      "source": [
        "Check the folder location and file for the finetuning inside given directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5Q95xMzGhcg",
        "outputId": "b3d5ac26-b716-4269-baf8-07cf3cf0f312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 910664\n",
            "-rw-r--r-- 1 root root      3788 Mar 16 06:50 build_openwebtext_pretraining_dataset.py\n",
            "-rw-r--r-- 1 root root      8801 Mar 16 06:50 build_pretraining_dataset.py\n",
            "-rw-r--r-- 1 root root      7607 Mar 16 06:50 configure_finetuning.py\n",
            "-rw-r--r-- 1 root root      5265 Mar 16 06:50 configure_pretraining.py\n",
            "-rw-r--r-- 1 root root      1101 Mar 16 06:50 CONTRIBUTING.md\n",
            "-rw-r--r-- 1 root root   4370528 Mar 14 23:23 dev.json\n",
            "drwxr-xr-x 2 root root      4096 Mar  3 21:55 \u001b[0m\u001b[01;34melectra_base\u001b[0m/\n",
            "-rw-r--r-- 1 root root 885890161 Mar  6 20:00 electra_base.zip\n",
            "drwxr-xr-x 5 root root      4096 Mar 16 06:50 \u001b[01;34mfinetune\u001b[0m/\n",
            "-rw-r--r-- 1 root root     11358 Mar 16 06:50 LICENSE\n",
            "drwxr-xr-x 2 root root      4096 Mar 16 06:50 \u001b[01;34mmodel\u001b[0m/\n",
            "drwxr-xr-x 2 root root      4096 Mar 16 06:50 \u001b[01;34mpretrain\u001b[0m/\n",
            "-rw-r--r-- 1 root root     15480 Mar 16 06:50 README.md\n",
            "-rw-r--r-- 1 root root     12663 Mar 16 06:50 run_finetuning.py\n",
            "-rw-r--r-- 1 root root     16518 Mar 16 06:50 run_pretraining.py\n",
            "-rw-r--r-- 1 root root  42123633 Mar 14 23:23 train.json\n",
            "drwxr-xr-x 2 root root      4096 Mar 16 06:50 \u001b[01;34mutil\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYAwq7V3W6hx"
      },
      "source": [
        "## **Create Data directory:** \n",
        "\n",
        "\n",
        "> Need to create a data directory at GCS (Google Cloud Storage) bucket, where you need to move Pre-trained Model at GCS (Google Cloud Storage) bucket and SQUAD dataset files as Local File System is not Supported on TPU. For that you need to provide your BUCKET name and Data DIRECTORY name.\n",
        "\n",
        "> If you don't move your pretrained model to TPU you may face an error. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh_R7weyzUn3"
      },
      "source": [
        "BUCKET = 'electra_finetuning' #@param {type:\"string\"}\n",
        "assert BUCKET, '*** Must specify an existing GCS bucket name ***'\n",
        "data_dir_name = 'data_dir' #@param {type:\"string\"}\n",
        "BUCKET_NAME = 'gs://{}'.format(BUCKET)\n",
        "DATA_DIR = 'gs://{}/{}'.format(BUCKET,data_dir_name)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzwfyeH-2BbH"
      },
      "source": [
        "### Create a Path inside GCS (Google Cloud Storage) bucket.\n",
        "\n",
        "> Make a new directory **'finetuning_data'** and in that create another one **'squad'** directory, to create a path **'data_dir/finetuning_data/squad/'** for copy the SQUAD dataset inside this path. It is a **default path** given in **Electra finetuning scripts** for **SQUAD dataset**. \n",
        "\n",
        "> In your bucket make a new folder **'models'** in 'data_dir' directory to create path **'data_dir/models/'** for copy the **Electra pretrainded model** inside this path which is a default location for pretrained model as per fintuning script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0jag_0jlWVk"
      },
      "source": [
        "## **Move Pretrained Model to GCS Bucket** \n",
        "\n",
        "> The **gsutil** **mv** command allows you to move data between your local file system and the cloud, move data within the cloud, and move data between cloud storage providers.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkxeI0GI0Bqe",
        "outputId": "179244e4-a27c-465b-a875-b07029a05f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "!gsutil mv /content/electra/electra_base/ gs://$BUCKET_NAME/data_dir/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/electra/electra_base/electra_base.index [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/ 16.6 KiB]                                                \r/ [1 files][ 16.6 KiB/ 16.6 KiB]                                                \rRemoving file:///content/electra/electra_base/electra_base.index...\n",
            "Copying file:///content/electra/electra_base/electra_base.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "/ [1 files][ 16.6 KiB/455.4 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Removing file:///content/electra/electra_base/electra_base.data-00000-of-00001...\n",
            "Copying file:///content/electra/electra_base/checkpoint [Content-Type=application/octet-stream]...\n",
            "Removing file:///content/electra/electra_base/checkpoint...\n",
            "Copying file:///content/electra/electra_base/vocab.txt [Content-Type=text/plain]...\n",
            "Removing file:///content/electra/electra_base/vocab.txt...\n",
            "\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying file:///content/electra/electra_base/electra_base.meta [Content-Type=application/octet-stream]...\n",
            "Removing file:///content/electra/electra_base/electra_base.meta...\n",
            "\n",
            "Operation completed over 5 objects/911.8 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6N6HJTr8L1T"
      },
      "source": [
        "## **Move SQUAD datasets for pretrained Model:**\n",
        "\n",
        "> Move the SQUAD dataset files into the bucket path '$BUCKET_NAME/data_dir/finetuning_data/squad' by using below command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E7r-Q8T281N",
        "outputId": "dafcccfc-7e07-4ace-979e-e2b80ab86e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "!gsutil mv /content/electra/train.json gs://$BUCKET_NAME/data_dir/finetuning_data/squad\n",
        "!gsutil mv /content/electra/dev.json gs://$BUCKET_NAME/data_dir/finetuning_data/squad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/electra/train.json [Content-Type=application/json]...\n",
            "Removing file:///content/electra/train.json...\n",
            "\n",
            "Operation completed over 1 objects/40.2 MiB.                                     \n",
            "Copying file:///content/electra/dev.json [Content-Type=application/json]...\n",
            "Removing file:///content/electra/dev.json...\n",
            "\n",
            "Operation completed over 1 objects/4.2 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHG3iA24q_K8"
      },
      "source": [
        "##**Fine Tuning:**\n",
        "\n",
        "> Below is the command to run the training. To run the training on TPU you need to make sure about below Hyperparameter, that is tpu must be true and provide the tpu_address that we have find out above.\n",
        "1.   --use_tpu=True\n",
        "2.   --tpu_name=YOUR_TPU_ADDRESS\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKogXfGsVP6r"
      },
      "source": [
        "Check the path of finetuning script by using 'pwd' command and run the finetuning script given next to the 'pwd' cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn-0Wfl8VOdP"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbTOfLe2DBpf",
        "outputId": "c63bd978-8bc7-4bad-d512-0e867caad4e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 run_finetuning.py --data-dir gs://$BUCKET_NAME/data_dir/ --model-name electra_base --hparams '{\"model_size\": \"base\", \"task_names\": [\"squad\"] , \"use_tpu\": \"True\", \"tpu_name\": \"grpc://10.53.108.138:8470\", \"num_tpu_cores\":8}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Config: model=electra_base, trial 1/1\n",
            "================================================================================\n",
            "answerable_classifier True\n",
            "answerable_uses_start_logits True\n",
            "answerable_weight 0.5\n",
            "beam_size 20\n",
            "data_dir gs://electra_finetuning/data_dir/\n",
            "debug False\n",
            "do_eval True\n",
            "do_lower_case True\n",
            "do_train True\n",
            "doc_stride 128\n",
            "double_unordered True\n",
            "embedding_size None\n",
            "eval_batch_size 32\n",
            "gcp_project None\n",
            "init_checkpoint gs://electra_finetuning/data_dir/models/electra_base\n",
            "iterations_per_loop 1000\n",
            "joint_prediction True\n",
            "keep_all_models True\n",
            "layerwise_lr_decay 0.8\n",
            "learning_rate 0.0001\n",
            "log_examples False\n",
            "max_answer_length 30\n",
            "max_query_length 64\n",
            "max_seq_length 512\n",
            "model_dir gs://electra_finetuning/data_dir/models/electra_base/finetuning_models/squad_model\n",
            "model_hparam_overrides {}\n",
            "model_name electra_base\n",
            "model_size base\n",
            "n_best_size 20\n",
            "n_writes_test 5\n",
            "num_tpu_cores 8\n",
            "num_train_epochs 2.0\n",
            "num_trials 1\n",
            "predict_batch_size 32\n",
            "preprocessed_data_dir gs://electra_finetuning/data_dir/models/electra_base/finetuning_tfrecords/squad_tfrecords\n",
            "qa_eval_file <built-in method format of str object at 0x7fcf2286a250>\n",
            "qa_na_file <built-in method format of str object at 0x7fcf22867f60>\n",
            "qa_na_threshold -2.75\n",
            "qa_preds_file <built-in method format of str object at 0x7fcf2286a1c8>\n",
            "raw_data_dir <built-in method format of str object at 0x7fcf23b707e8>\n",
            "results_pkl gs://electra_finetuning/data_dir/models/electra_base/results/squad_results.pkl\n",
            "results_txt gs://electra_finetuning/data_dir/models/electra_base/results/squad_results.txt\n",
            "save_checkpoints_steps 1000000\n",
            "task_names ['squad']\n",
            "test_predictions <built-in method format of str object at 0x7fcf22862160>\n",
            "tpu_job_name None\n",
            "tpu_name grpc://10.53.108.138:8470\n",
            "tpu_zone None\n",
            "train_batch_size 32\n",
            "use_tfrecords_if_existing True\n",
            "use_tpu True\n",
            "vocab_file gs://electra_finetuning/data_dir/models/electra_base/vocab.txt\n",
            "vocab_size 30522\n",
            "warmup_proportion 0.1\n",
            "weight_decay_rate 0.01\n",
            "write_distill_outputs False\n",
            "write_test_outputs False\n",
            "\n",
            "Loading dataset squad_train\n",
            "Existing tfrecords not found so creating\n",
            "130319 examples created, 0 failures\n",
            "Writing example 0 of 130319\n",
            "Writing example 2000 of 130319\n",
            "Writing example 4000 of 130319\n",
            "Writing example 6000 of 130319\n",
            "Writing example 8000 of 130319\n",
            "Writing example 10000 of 130319\n",
            "Writing example 12000 of 130319\n",
            "Writing example 14000 of 130319\n",
            "Writing example 16000 of 130319\n",
            "Writing example 18000 of 130319\n",
            "Writing example 20000 of 130319\n",
            "Writing example 22000 of 130319\n",
            "Writing example 24000 of 130319\n",
            "Writing example 26000 of 130319\n",
            "Writing example 28000 of 130319\n",
            "Writing example 30000 of 130319\n",
            "Writing example 32000 of 130319\n",
            "Writing example 34000 of 130319\n",
            "Writing example 36000 of 130319\n",
            "Writing example 38000 of 130319\n",
            "Writing example 40000 of 130319\n",
            "Writing example 42000 of 130319\n",
            "Writing example 44000 of 130319\n",
            "Writing example 46000 of 130319\n",
            "Writing example 48000 of 130319\n",
            "Writing example 50000 of 130319\n",
            "Writing example 52000 of 130319\n",
            "Writing example 54000 of 130319\n",
            "Writing example 56000 of 130319\n",
            "Writing example 58000 of 130319\n",
            "Writing example 60000 of 130319\n",
            "Writing example 62000 of 130319\n",
            "Writing example 64000 of 130319\n",
            "Writing example 66000 of 130319\n",
            "Writing example 68000 of 130319\n",
            "Writing example 70000 of 130319\n",
            "Writing example 72000 of 130319\n",
            "Writing example 74000 of 130319\n",
            "Writing example 76000 of 130319\n",
            "Writing example 78000 of 130319\n",
            "Writing example 80000 of 130319\n",
            "Writing example 82000 of 130319\n",
            "Writing example 84000 of 130319\n",
            "Writing example 86000 of 130319\n",
            "Writing example 88000 of 130319\n",
            "Writing example 90000 of 130319\n",
            "Writing example 92000 of 130319\n",
            "Writing example 94000 of 130319\n",
            "Writing example 96000 of 130319\n",
            "Writing example 98000 of 130319\n",
            "Writing example 100000 of 130319\n",
            "Writing example 102000 of 130319\n",
            "Writing example 104000 of 130319\n",
            "Writing example 106000 of 130319\n",
            "Writing example 108000 of 130319\n",
            "Writing example 110000 of 130319\n",
            "Writing example 112000 of 130319\n",
            "Writing example 114000 of 130319\n",
            "Writing example 116000 of 130319\n",
            "Writing example 118000 of 130319\n",
            "Writing example 120000 of 130319\n",
            "Writing example 122000 of 130319\n",
            "Writing example 124000 of 130319\n",
            "Writing example 126000 of 130319\n",
            "Writing example 128000 of 130319\n",
            "Writing example 130000 of 130319\n",
            "================================================================================\n",
            "Start training: model=electra_base, trial 1/1\n",
            "================================================================================\n",
            "Training for 8162 steps\n",
            "2020-03-16 07:08:24.119500: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "2020-03-16 07:08:24.402945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-16 07:08:24.405686: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-03-16 07:08:24.405737: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d1285cf1e744): /proc/driver/nvidia/version does not exist\n",
            "Building model...\n",
            "Building complete\n",
            "2020-03-16 07:09:19.841984: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "1000/8162 = 12.3%, SPS: 5.8, ELAP: 2:53, ETA: 20:42\n",
            "2000/8162 = 24.5%, SPS: 6.3, ELAP: 5:16, ETA: 16:13\n",
            "3000/8162 = 36.8%, SPS: 6.6, ELAP: 7:35, ETA: 13:02\n",
            "4000/8162 = 49.0%, SPS: 6.7, ELAP: 9:54, ETA: 10:18\n",
            "5000/8162 = 61.3%, SPS: 6.8, ELAP: 12:13, ETA: 7:43\n",
            "6000/8162 = 73.5%, SPS: 6.9, ELAP: 14:31, ETA: 5:14\n",
            "7000/8162 = 85.8%, SPS: 6.9, ELAP: 16:50, ETA: 2:48\n",
            "8000/8162 = 98.0%, SPS: 7.0, ELAP: 19:09, ETA: 23\n",
            "\n",
            "================================================================================\n",
            "Run dev set evaluation: model=electra_base, trial 1/1\n",
            "================================================================================\n",
            "Evaluating squad\n",
            "Loading dataset squad_dev\n",
            "Existing tfrecords not found so creating\n",
            "11873 examples created, 0 failures\n",
            "Writing example 0 of 11873\n",
            "Writing example 2000 of 11873\n",
            "Writing example 4000 of 11873\n",
            "Writing example 6000 of 11873\n",
            "Writing example 8000 of 11873\n",
            "Writing example 10000 of 11873\n",
            "Building model...\n",
            "Building complete\n",
            "squad: HasAns_exact: 78.32 - HasAns_f1: 83.61 - HasAns_total: 5928.00 - NoAns_exact: 88.49 - NoAns_f1: 88.49 - NoAns_total: 5945.00 - best_exact: 83.48 - best_exact_thresh: -2.72 - best_f1: 86.15 - best_f1_thresh: -2.65 - exact: 83.42 - f1: 86.06 - total: 11873.00\n",
            "\n",
            "Writing results to gs://electra_finetuning/data_dir/models/electra_base/results/squad_results.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gczlQwLO_tkg"
      },
      "source": [
        "### Location of Trained Model and Evaluation Result:\n",
        "\n",
        ">After Training, location of your finetuned model inside your bucket is '**$BUCKET_NAME/data_dir/models/electra_base/finetuning_models/squad_model_1/**' in your bucket.\n",
        "\n",
        "> Evaluation result for the 'dev.json' file is inside the bucket path **'$BUCKET_NAME/data_dir/models/electra_base/results/squad_qa'** in the json format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFPt0QfRrEcx"
      },
      "source": [
        "##**Prediction:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHZJIZFYUWCs"
      },
      "source": [
        "Check finetuning script 'run_finetuning.py' inside 'electra' folder by using below command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyOGhbxJUPXF",
        "outputId": "004443d1-192f-40e7-e941-8424f2d0f647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 865256\n",
            "-rw-r--r-- 1 root root      3788 Mar 16 06:50 build_openwebtext_pretraining_dataset.py\n",
            "-rw-r--r-- 1 root root      8801 Mar 16 06:50 build_pretraining_dataset.py\n",
            "-rw-r--r-- 1 root root      7607 Mar 16 06:50 configure_finetuning.py\n",
            "-rw-r--r-- 1 root root      5265 Mar 16 06:50 configure_pretraining.py\n",
            "-rw-r--r-- 1 root root      1101 Mar 16 06:50 CONTRIBUTING.md\n",
            "drwxr-xr-x 2 root root      4096 Mar 16 06:56 \u001b[0m\u001b[01;34melectra_base\u001b[0m/\n",
            "-rw-r--r-- 1 root root 885890161 Mar  6 20:00 electra_base.zip\n",
            "drwxr-xr-x 6 root root      4096 Mar 16 06:59 \u001b[01;34mfinetune\u001b[0m/\n",
            "-rw-r--r-- 1 root root     11358 Mar 16 06:50 LICENSE\n",
            "drwxr-xr-x 3 root root      4096 Mar 16 06:59 \u001b[01;34mmodel\u001b[0m/\n",
            "drwxr-xr-x 3 root root      4096 Mar 16 06:59 \u001b[01;34mpretrain\u001b[0m/\n",
            "drwxr-xr-x 2 root root      4096 Mar 16 06:59 \u001b[01;34m__pycache__\u001b[0m/\n",
            "-rw-r--r-- 1 root root     15480 Mar 16 06:50 README.md\n",
            "-rw-r--r-- 1 root root     12663 Mar 16 06:50 run_finetuning.py\n",
            "-rw-r--r-- 1 root root     16518 Mar 16 06:50 run_pretraining.py\n",
            "drwxr-xr-x 3 root root      4096 Mar 16 06:59 \u001b[01;34mutil\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KqTxcHK-IKI"
      },
      "source": [
        "Remove all the files from the path of the SQUAD dataset of your bucket:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nme6G9sA953G",
        "outputId": "809c0643-1e97-4450-e535-3b35bff7c251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!gsutil rm gs://$BUCKET_NAME/data_dir/finetuning_data/squad/train.json\n",
        "!gsutil rm gs://$BUCKET_NAME/data_dir/finetuning_data/squad/dev.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing gs://electra_finetuning/data_dir/finetuning_data/squad/train.json...\n",
            "/ [1 objects]                                                                   \n",
            "Operation completed over 1 objects.                                              \n",
            "Removing gs://electra_finetuning/data_dir/finetuning_data/squad/dev.json...\n",
            "/ [1 objects]                                                                   \n",
            "Operation completed over 1 objects.                                              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAptznnCdX8d"
      },
      "source": [
        "### **Create Testing File**\n",
        "\n",
        "\n",
        "> We are creating **'dev.json'** as a blank json file as this is the default evaluating file name for the inference of finetuned model as given in the finetuning script and then writing the data in SQUAD format in the file.\n",
        "\n",
        "*   **touch** is used to create a file\n",
        "*   **%%writefile** is used to write a file in the colab\n",
        "\n",
        "> You can pass your own questions and context in the below file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoT__iSecn-B"
      },
      "source": [
        "!touch dev.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrxuoRNCcsnf",
        "outputId": "f7472f12-ceaa-44bf-cdd5-7099c377ac9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile dev.json\n",
        "{\n",
        "    \"version\": \"v2.0\",\n",
        "    \"data\": [\n",
        "        {\n",
        "            \"title\": \"your_title\",\n",
        "            \"paragraphs\": [\n",
        "                {\n",
        "                    \"qas\": [\n",
        "                        {\n",
        "                            \"question\": \"Who is current CEO?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9628\",\n",
        "                            \"is_impossible\": \"\",\n",
        "                            \"answers\":[]\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"Who founded google?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b9629\",\n",
        "                            \"is_impossible\": \"\",\n",
        "                            \"answers\":[]\n",
        "                        },\n",
        "                        {\n",
        "                            \"question\": \"when did IPO take place?\",\n",
        "                            \"id\": \"56ddde6b9a695914005b962a\",\n",
        "                            \"is_impossible\": \"\",\n",
        "                            \"answers\":[]\n",
        "                        }\n",
        "                    ],\n",
        "                    \"context\": \"Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock. They incorporated Google as a privately held company on September 4, 1998. An initial public offering (IPO) took place on August 19, 2004, and Google moved to its headquarters in Mountain View, California, nicknamed the Googleplex. In August 2015, Google announced plans to reorganize its various interests as a conglomerate called Alphabet Inc. Google is Alphabet's leading subsidiary and will continue to be the umbrella company for Alphabet's Internet interests. Sundar Pichai was appointed CEO of Google, replacing Larry Page who became the CEO of Alphabet.\"                \n",
        "                 }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting dev.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozC0ADLL9uxN"
      },
      "source": [
        "###**Move Inference input file:**\n",
        "Move this 'dev.json' file from local path to squad dataset path of your bucket by using below command. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw97iZie9uNG",
        "outputId": "22b62511-d600-4655-8737-89d9bb81e89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!gsutil mv /content/electra/dev.json gs://$BUCKET_NAME/data_dir/finetuning_data/squad/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/electra/dev.json [Content-Type=application/json]...\n",
            "Removing file:///content/electra/dev.json...\n",
            "\n",
            "Operation completed over 1 objects/1.9 KiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_tzerhBkMIq",
        "outputId": "712de5ad-22b2-454b-f6ad-2b1296de5967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build_openwebtext_pretraining_dataset.py  electra_base.zip  README.md\n",
            "build_pretraining_dataset.py              \u001b[0m\u001b[01;34mfinetune\u001b[0m/         run_finetuning.py\n",
            "configure_finetuning.py                   LICENSE           run_pretraining.py\n",
            "configure_pretraining.py                  \u001b[01;34mmodel\u001b[0m/            \u001b[01;34mutil\u001b[0m/\n",
            "CONTRIBUTING.md                           \u001b[01;34mpretrain\u001b[0m/\n",
            "\u001b[01;34melectra_base\u001b[0m/                             \u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soY3sRQcYg1W"
      },
      "source": [
        "Run the below command and get prediction for the given **'dev.json'** file. The path for the prediction file inside your bucket will be **'$BUCKET_NAME/data_dir/models/electra_base/results/squad_qa/squad_predict.json'**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VudqEo9rEKe",
        "outputId": "fc84c38b-304f-4818-bb9c-791ad801dc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 run_finetuning.py --data-dir gs://$BUCKET_NAME/data_dir --model-name electra_base/ --hparams '{\"do_train\": false, \"do_eval\": true, \"model_size\": \"base\", \"task_names\": [\"squad\"], \"init_checkpoint\": \"gs://$BUCKET_NAME/data_dir/models/electra_base/finetuning_models/squad_model_1\", \"use_tpu\": \"True\", \"tpu_name\": \"grpc://10.53.108.138:8470\", \"num_tpu_cores\":8}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Config: model=electra_base/, trial 1/1\n",
            "================================================================================\n",
            "answerable_classifier True\n",
            "answerable_uses_start_logits True\n",
            "answerable_weight 0.5\n",
            "beam_size 20\n",
            "data_dir gs://electra_finetuning/data_dir\n",
            "debug False\n",
            "do_eval True\n",
            "do_lower_case True\n",
            "do_train False\n",
            "doc_stride 128\n",
            "double_unordered True\n",
            "embedding_size None\n",
            "eval_batch_size 32\n",
            "gcp_project None\n",
            "init_checkpoint gs://electra_finetuning/data_dir/models/electra_base/finetuning_models/squad_model_1\n",
            "iterations_per_loop 1000\n",
            "joint_prediction True\n",
            "keep_all_models True\n",
            "layerwise_lr_decay 0.8\n",
            "learning_rate 0.0001\n",
            "log_examples False\n",
            "max_answer_length 30\n",
            "max_query_length 64\n",
            "max_seq_length 512\n",
            "model_dir gs://electra_finetuning/data_dir/models/electra_base/finetuning_models/squad_model\n",
            "model_hparam_overrides {}\n",
            "model_name electra_base/\n",
            "model_size base\n",
            "n_best_size 20\n",
            "n_writes_test 5\n",
            "num_tpu_cores 8\n",
            "num_train_epochs 2.0\n",
            "num_trials 1\n",
            "predict_batch_size 32\n",
            "preprocessed_data_dir gs://electra_finetuning/data_dir/models/electra_base/finetuning_tfrecords/squad_tfrecords\n",
            "qa_eval_file <built-in method format of str object at 0x7f25e45b61c8>\n",
            "qa_na_file <built-in method format of str object at 0x7f25e45aef60>\n",
            "qa_na_threshold -2.75\n",
            "qa_preds_file <built-in method format of str object at 0x7f25e45b62d8>\n",
            "raw_data_dir <built-in method format of str object at 0x7f25e45cb098>\n",
            "results_pkl gs://electra_finetuning/data_dir/models/electra_base/results/squad_results.pkl\n",
            "results_txt gs://electra_finetuning/data_dir/models/electra_base/results/squad_results.txt\n",
            "save_checkpoints_steps 1000000\n",
            "task_names ['squad']\n",
            "test_predictions <built-in method format of str object at 0x7f25e45ac1f8>\n",
            "tpu_job_name None\n",
            "tpu_name grpc://10.53.108.138:8470\n",
            "tpu_zone None\n",
            "train_batch_size 32\n",
            "use_tfrecords_if_existing True\n",
            "use_tpu True\n",
            "vocab_file gs://electra_finetuning/data_dir/models/electra_base/vocab.txt\n",
            "vocab_size 30522\n",
            "warmup_proportion 0.1\n",
            "weight_decay_rate 0.01\n",
            "write_distill_outputs False\n",
            "write_test_outputs False\n",
            "\n",
            "================================================================================\n",
            "Run dev set evaluation: model=electra_base/, trial 1/1\n",
            "================================================================================\n",
            "Evaluating squad\n",
            "Loading dataset squad_dev\n",
            "3 examples created, 0 failures\n",
            "2020-03-16 08:36:31.425794: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "2020-03-16 08:36:32.769500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-16 08:36:32.771356: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-03-16 08:36:32.771528: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d1285cf1e744): /proc/driver/nvidia/version does not exist\n",
            "Building model...\n",
            "Building complete\n",
            "squad: NoAns_exact: 33.33 - NoAns_f1: 33.33 - NoAns_total: 3.00 - best_exact: 100.00 - best_exact_thresh: 0.00 - best_f1: 100.00 - best_f1_thresh: 0.00 - exact: 33.33 - f1: 33.33 - total: 3.00\n",
            "\n",
            "Writing results to gs://electra_finetuning/data_dir/models/electra_base/results/squad_results.txt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}